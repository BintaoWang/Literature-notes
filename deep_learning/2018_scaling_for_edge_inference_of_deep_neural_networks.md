# Note for [Scaling for edge inference of deep neural networks](https://cadlab.cs.ucla.edu/beta/cadlab/sites/default/files/publications/Shi_et_al_Perspective_1524052852_1.pdf)
## 摘要
&nbsp;&emsp;&ensp;DNNs 从先进制造到自动驾驶等一系列应用提供了巨大潜能。一个清晰的趋势就是DNN网络规模呈指数式的增长和随着带来的计算复杂度和内存消耗的增长。然而，在嵌入式设备进行本地计算，且尺寸和功率有限的边缘计算的性能和能量效率受限于工艺的规模。本文分析了最新的数据并且指出数据科学家所需的计算复杂度和能量效率与硬件架构师所提供的可用硬件能力之间的逐渐扩大的差距。同时本文讨论了各式各样的用于弥合差距的架构和算法。<br>

## 背景概述

- DNNs表现优越的应用场景：图像识别、[Go游戏](https://www.nature.com/articles/nature16961)、疾病诊断、实时语言翻译和自动驾驶。上述成就归功于逐渐增长的算力和逐渐丰富的数据，随着更快的计算节点组成的更大的集群以更低的成本和更小的外形变得可用，更多数据可以被用来大型的DNNs。<br>
- 随着推理准确度的提升，模型规模呈现指数式上升。这种趋势对于可通过互联网获取算力的网络不足以构成挑战，但是对于安全、隐私和延迟至关重要的嵌入式设备上的边缘计算，推理必须在本地或者边缘互联网完成，并且出于资源有限，这些算力受限于严格的面积和功耗约束<br>



