# Note for [Scaling for edge inference of deep neural networks](https://cadlab.cs.ucla.edu/beta/cadlab/sites/default/files/publications/Shi_et_al_Perspective_1524052852_1.pdf)
## 摘要
&nbsp;&emsp;&ensp;DNNs 从先进制造到自动驾驶等一系列应用提供了巨大潜能。一个清晰的趋势就是DNN网络规模呈指数式的增长和随着带来的计算复杂度和内存消耗的增长。然而，在嵌入式设备进行本地计算，且尺寸和功率有限的边缘计算的性能和能量效率受限于工艺的规模。本文分析了最新的数据并且指出数据科学家所需的计算复杂度和能量效率与硬件架构师所提供的可用硬件能力之间的逐渐扩大的间隙。同时本文讨论了各式各样的用于弥合间隙的架构和算法。<br>

## 背景概述

- DNNs表现优越的应用场景：图像识别、[Go游戏](https://www.nature.com/articles/nature16961)、疾病诊断、实时语言翻译和自动驾驶。上述成就归功于逐渐增长的算力和逐渐丰富的数据，随着更快的计算节点组成的更大的集群以更低的成本和更小的外形变得可用，更多数据可以被用来大型的DNNs。<br>
- 随着推理准确度的提升，模型规模呈现指数式上升。这种趋势对于可通过互联网获取算力的网络不足以构成挑战，但是对于安全、隐私和延迟至关重要的嵌入式设备上的边缘计算，推理必须在本地或者边缘互联网完成，并且出于资源有限，这些算力受限于严格的面积和功耗约束<br>
- 为了解决逐渐增长的模型尺寸带来的算力需求，硬件架构必须探索压缩技术来完成高效边缘推理，在最小化精度损失的情况下，降低功率和使用面积的开销。由于很多数据师通过设计更复杂的DNNs来提升推理准确度，因此在数据师和硬件架构师必然有一场角逐。基于[摩尔定律](https://zh.wikipedia.org/wiki/%E6%91%A9%E5%B0%94%E5%AE%9A%E5%BE%8B)的CMOS规模化已经为硬件架构师提供了一条相对简单的道路来适应逐渐增长的模型尺寸。随着CMOS工艺规模化趋势的减缓，为NN定制化设计的先进架构已经出现。基于这个角度，本文证实了基于摩尔定律的CMOS规模化与DNNs边缘化之间间隙的存在，并讨论了弥补这种间隙的各种各样的架构和算法。<br>

## 间隙
通过分析最近的数据，本文展示了介于追求更高准确度而设计更大DNNs的数据科学家和设计试图适应上述DNNs架构的硬件架构师之间的间隙。同时，伴随着检测误差的指数式下降，模型层数、参数量和计算量的指数上升。<br>
1. 性能间隙。
> - 模型操作数伴随着检测误差的指数下降而指数上升。即使从2014年提出并行结构化优化，能显著降低操作数的GooglNet之后，模型操作数仍以指数上升。<br>
 （补充学习：并行结构化优化[[18](https://arxiv.org/pdf/1802.03646.pdf)\  [19](https://en.wikipedia.org/wiki/List_of_Nvidia_graphics_processing_units)]）<br>
> - GPUs、FPGAs、ASICs是适应边缘计算模型的常用硬件平台。![图3](https://github.com/BintaoWang/Literature-notes/blob/master/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202022-03-25%20203150.jpg)decpits 模型的性能和算力平台的性能密度。GPU:2011-2014年出于架构和工艺没有进展，高端GPU PD保持平稳。2015年，相关工艺从28nm集成到20nm，PD提高到两倍左右。2017年，相关工艺集成到12nm时，PD出现了略微下降，这是由于大型的内存和高带宽IO需要更大的面积，之后基本饱和。为DNNs而设计的ASIC因顾及不同指标而不同，如性能、功率（Myriad 2, Eyeriss and EIE）、或者速度。但是由于高度定制化，ASICs的性能高于GPUs和FPGAs。总之2011-2013PD指数式上升，之后保持平稳，且都在摩尔定律的预言之下。预计当工艺达到5nm时，PD将不会上升。<br>
